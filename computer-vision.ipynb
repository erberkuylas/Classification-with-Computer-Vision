{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2333429,"sourceType":"datasetVersion","datasetId":1408532}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:42:31.926471Z","iopub.execute_input":"2024-12-22T20:42:31.927126Z","iopub.status.idle":"2024-12-22T20:42:59.436179Z","shell.execute_reply.started":"2024-12-22T20:42:31.927063Z","shell.execute_reply":"2024-12-22T20:42:59.435215Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Kullanılan Kütüphaneler\n\nAşağıdaki kütüphaneler, model oluşturma, eğitim, değerlendirme ve görselleştirme işlemleri için kullanılır:\n\n1. **os**: Dosya ve dizin işlemleri için kullanılır.\n2. **cv2 (OpenCV)**: Görsel işleme için kullanılır. Görsellerin okunması ve boyutlandırılması işlemleri yapılır.\n3. **numpy**: Matematiksel işlemler için kullanılan temel kütüphane, veri manipülasyonu için kullanılır.\n4. **sklearn.model_selection.train_test_split**: Veriyi eğitim ve test setlerine ayırmak için kullanılır.\n5. **tensorflow.keras.preprocessing.image.ImageDataGenerator**: Veri artırma için kullanılır, eğitim verisinin çeşitlendirilmesi amacıyla.\n6. **matplotlib.pyplot**: Veri görselleştirme için kullanılır. Eğitim doğruluğu ve kaybı gibi metrikler çizilir.\n7. **tensorflow.keras.callbacks.EarlyStopping ve ReduceLROnPlateau**: Modelin eğitimini erken durdurmak ve öğrenme oranını dinamik olarak azaltmak için kullanılır.\n8. **tensorflow.keras.utils.to_categorical**: Etiketleri one-hot encoding formatına dönüştürmek için kullanılır.\n9. **tensorflow.keras.models.Sequential**: Derin öğrenme modelinin yapılandırılması için kullanılır.\n10. **tensorflow.keras.layers.Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization**: Derin öğrenme modelinin katmanlarını tanımlamak için kullanılır.\n11. **tensorflow.keras.regularizers.l2**: Modelin aşırı öğrenmesini engellemek için düzenleme teknikleri kullanılır.\n12. **sklearn.metrics.confusion_matrix, f1_score, accuracy_score**: Modelin doğruluğunu ve performansını değerlendirmek için kullanılır.\n13. **seaborn**: Karışıklık matrisi gibi görselleştirmeler için kullanılır.\n14. **keras.models.load_model**: Daha önce eğitilmiş bir modeli yüklemek için kullanılır.\n\n","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom keras.models import load_model\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:42:59.437584Z","iopub.execute_input":"2024-12-22T20:42:59.437859Z","iopub.status.idle":"2024-12-22T20:42:59.443883Z","shell.execute_reply.started":"2024-12-22T20:42:59.437833Z","shell.execute_reply":"2024-12-22T20:42:59.442931Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Görsellerin Yüklenmesi ve Ön İşleme\n\nBu kod, belirli sınıflara ait görselleri bir klasörden alıp, görselleri yeniden boyutlandırarak normalleştirir ve etiketler ile birlikte bir listeye ekler.\n\n### Adımlar:\n1. **Görsel Klasörü ve Sınıflar**: Görsellerin bulunduğu klasör `image_dir` olarak tanımlanır. Çalışılacak sınıflar `classes` listesinde belirtilir.\n2. **Görsel ve Etiket Listeleri**: Görsellerin ve etiketlerin tutulacağı boş listeler (`X` ve `y`) oluşturulur.\n3. **Görsellerin Yüklenmesi**: \n    - Her bir sınıf için belirtilen alt klasörden ilk 650 görsel alınır.\n    - Görseller, `cv2.imread` ile okunur, 224x224 boyutuna yeniden boyutlandırılır ve `255` ile normalleştirilir.\n    - Görsel ve etiketler sırasıyla `X` ve `y` listelerine eklenir.\n4. **Veri Seti Dönüştürme**: `X` ve `y` listeleri NumPy dizilerine dönüştürülür.\n5. **Sonuç**: Veri setinin boyutları ekrana yazdırılır.\n6. \n### Çıktı:\n- Görsellerin ve etiketlerin boyutları yazdırılır (`X.shape`, `y.shape`).\n","metadata":{}},{"cell_type":"code","source":"# Görsellerin bulunduğu klasör\nimage_dir = '/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages'\n\n# Kullanılacak sınıflar\nclasses = ['collie', 'dolphin', 'elephant', 'fox', 'moose', 'rabbit', 'sheep', 'squirrel', 'giant panda', 'polar bear']\n\n# Görsellerin listeleneceği liste\nX = []  # Görseller\ny = []  # Etiketler\n\n# Her sınıf için sadece ilk 650 görseli alalım\nfor label_idx, class_name in enumerate(classes):\n    class_dir = os.path.join(image_dir, class_name)\n    \n    # Alt dizinde görsellerin olup olmadığını kontrol et\n    if os.path.exists(class_dir):\n        images = os.listdir(class_dir)\n        \n        # İlk 650 görseli al\n        selected_images = images[:650]\n        \n        for img_name in selected_images:\n            img_path = os.path.join(class_dir, img_name)\n            img = cv2.imread(img_path)\n            \n            # Resmi yeniden boyutlandırma\n            img_resized = cv2.resize(img, (224, 224))  # 224x224 boyutunda\n            img_normalized = img_resized / 255.0  # Normalizasyon\n            \n            X.append(img_normalized)\n            y.append(label_idx)  # Etiketi sayısal hale getirdik\n    else:\n        print(f\"Class {class_name} not found in the directory: {class_dir}\")\n\n# NumPy dizisine dönüştürme\nX = np.array(X)\ny = np.array(y)\n\n# Veri setinin boyutlarını kontrol edelim\nprint(f\"X shape: {X.shape}, y shape: {y.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:42:59.445211Z","iopub.execute_input":"2024-12-22T20:42:59.445574Z","iopub.status.idle":"2024-12-22T20:43:57.434389Z","shell.execute_reply.started":"2024-12-22T20:42:59.445535Z","shell.execute_reply":"2024-12-22T20:43:57.433440Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Eğitim ve Test Setlerine Ayırma\n\nBu kod, görsel veri setini eğitim ve test setlerine ayırır.\n\n### Adımlar:\n1. **Veriyi Bölme**: \n    - `train_test_split` fonksiyonu, veri setini eğitim ve test setlerine ayırır.\n    - `test_size=0.3` parametresi ile verinin %30'u test setine ayrılır.\n    - `random_state=42` parametresi ile rastgelelikin sabitlenmesi sağlanır.\n2. **Boyut Kontrolü**: Eğitim ve test setlerinin boyutları `shape` fonksiyonu ile kontrol edilir.\n\n### Çıktı:\n- Eğitim ve test setlerinin boyutları ekrana yazdırılır (`X_train.shape`, `X_test.shape`, `y_train.shape`, `y_test.shape`).\n","metadata":{}},{"cell_type":"code","source":"# Veriyi eğitim ve test setlerine ayıralım\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Eğitim ve test setlerinin boyutlarını kontrol edelim\nprint(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\nprint(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:43:57.436027Z","iopub.execute_input":"2024-12-22T20:43:57.436337Z","iopub.status.idle":"2024-12-22T20:43:59.055095Z","shell.execute_reply.started":"2024-12-22T20:43:57.436310Z","shell.execute_reply":"2024-12-22T20:43:59.054248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Etiketleri One-Hot Encoding Formatına Dönüştürme\n\nBu kod, etiketleri one-hot encoding formatına dönüştürerek her sınıf için ayrı bir sütun oluşturur.\n\n### Adımlar:\n1. **One-Hot Encoding**: \n    - `to_categorical` fonksiyonu ile `y_train` ve `y_test` etiketleri, her sınıf için birer sütun oluşturacak şekilde one-hot encoding formatına dönüştürülür.\n    - `num_classes=10` parametresi, toplam 10 sınıf olduğunu belirtir.\n2. **Boyut Kontrolü**: Yeni etiket dizilerinin boyutları `shape` fonksiyonu ile kontrol edilir.\n\n### Çıktı:\n- One-hot encoding işleminden sonra `y_train.shape` ve `y_test.shape` boyutları ekrana yazdırılır.\n","metadata":{}},{"cell_type":"code","source":"# Etiketleri one-hot encoding formatına dönüştürme\ny_train = to_categorical(y_train, num_classes=10)\ny_test = to_categorical(y_test, num_classes=10)\n\n# Yeni boyutları kontrol et\nprint(f\"y_train shape after one-hot encoding: {y_train.shape}\")\nprint(f\"y_test shape after one-hot encoding: {y_test.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:43:59.056395Z","iopub.execute_input":"2024-12-22T20:43:59.057062Z","iopub.status.idle":"2024-12-22T20:43:59.062455Z","shell.execute_reply.started":"2024-12-22T20:43:59.057019Z","shell.execute_reply":"2024-12-22T20:43:59.061572Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Veri Artırma için ImageDataGenerator Kullanımı\n\nBu kod, eğitim verisini artırmak için `ImageDataGenerator` sınıfını kullanarak çeşitli veri artırma tekniklerini uygular.\n\n### Adımlar:\n1. **Veri Artırma Ayarları**: \n    - `ImageDataGenerator` ile görseller üzerinde döndürme, kaydırma, yakınlaştırma, çevirme gibi teknikler uygulanır.\n    - Parametreler:\n        - `rotation_range=30`: Görselleri 30 dereceye kadar döndürme.\n        - `width_shift_range=0.2`: Yatayda %20'lik kaydırma.\n        - `height_shift_range=0.2`: Dikeyde %20'lik kaydırma.\n        - `shear_range=0.2`: Eğimli kaydırma.\n        - `zoom_range=0.2`: Yakınlaştırma.\n        - `horizontal_flip=True`: Yatay çevirme.\n        - `fill_mode='nearest'`: Yeni boş alanları en yakın pikselle doldurma.\n2. **Veri Artırma Uygulama**: \n    - `train_generator` ile eğitim verilerine artırma uygulanır, her seferinde 64 örnek alınır.\n3. **Örnek Görsel Gösterimi**:\n    - Artırılmış bir görsel `matplotlib` ile görselleştirilir.\n\n### Çıktı:\n- Augmente edilmiş bir örnek görsel ekranda gösterilir.\n","metadata":{}},{"cell_type":"code","source":"# Veri artırma için ImageDataGenerator kullanımı\ndatagen = ImageDataGenerator(\n    rotation_range=30,    # Resmi döndürme\n    width_shift_range=0.2,  # Yatay kaydırma\n    height_shift_range=0.2, # Dikey kaydırma\n    shear_range=0.2,      # Eğimli kaydırma\n    zoom_range=0.2,       # Yakınlaştırma\n    horizontal_flip=True, # Yatay çevirme\n    fill_mode='nearest'   # Boş alanı doldurma\n)\n# Eğitim setine veri artırma uygulama\ntrain_generator = datagen.flow(X_train, y_train, batch_size=64)\n\n# Augmente edilmiş bir örnek görüntü görmek için\nimport matplotlib.pyplot as plt\naugmented_img = next(datagen.flow(X_train, y_train, batch_size=1))[0][0]\nplt.imshow(augmented_img)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:43:59.063587Z","iopub.execute_input":"2024-12-22T20:43:59.064208Z","iopub.status.idle":"2024-12-22T20:44:00.991810Z","shell.execute_reply.started":"2024-12-22T20:43:59.064168Z","shell.execute_reply":"2024-12-22T20:44:00.990978Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modeli Oluşturma\n\nBu kod, derin öğrenme modeli oluşturur ve eğitim için derler.\n\n### Adımlar:\n1. **Model Yapısı**:\n    - `Sequential` model kullanılarak katmanlar sırayla eklenir.\n    \n2. **Konvolüsyon Katmanları**:\n    - 4 adet konvolüsyon katmanı (`Conv2D`) eklenir.\n    - Her katmanda `ReLU` aktivasyon fonksiyonu, `L2` regularizasyonu ve `MaxPooling2D` ile havuzlama yapılır.\n    - BatchNormalization ile her katmandan sonra normalizasyon uygulanır.\n\n3. **Fully Connected Katmanlar**:\n    - `Flatten` katmanı ile 2D çıktılar 1D'ye dönüştürülür.\n    - `Dense` katmanları ile tam bağlantılı katmanlar eklenir, her iki katman arasında `Dropout` ile aşırı uyum önlenir.\n    - İlk `Dense` katmanında 512 nöron, ikinci `Dense` katmanında ise 256 nöron bulunur.\n\n4. **Çıkış Katmanı**:\n    - 10 sınıflı çıkış için `softmax` aktivasyonu kullanılır.\n\n5. **Modelin Derlenmesi**:\n    - Adam optimizasyon algoritması ve `categorical_crossentropy` kayıp fonksiyonu kullanılarak model derlenir.\n    - Doğruluk metriği izlenir.\n\n6. **Model Özeti**:\n    - `model.summary()` fonksiyonu ile modelin yapısı ve katman bilgisi yazdırılır.\n\n### Çıktı:\n- Modelin katmanları ve her katmanın parametre sayıları yazdırılır.\n","metadata":{}},{"cell_type":"code","source":"# Modeli oluştur\nmodel = Sequential()\n\n# İlk Konvolüsyon Katmanı\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(224, 224, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# İkinci Konvolüsyon Katmanı\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Üçüncü Konvolüsyon Katmanı\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Dördüncü Konvolüsyon Katmanı\nmodel.add(Conv2D(256, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Fully Connected Katmanlar\nmodel.add(Flatten())  # Katmanı düzleştir\nmodel.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\nmodel.add(Dropout(0.5)) # Overfitting'i azaltmak için Dropout\n\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\nmodel.add(Dropout(0.7)) # Oranı biraz artırdık\n\n# Çıkış Katmanı (Softmax ile 10 sınıf)\nmodel.add(Dense(10, activation='softmax', kernel_regularizer=l2(0.01)))\n\n# Modeli derle\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00008),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Model özeti\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:44:00.993170Z","iopub.execute_input":"2024-12-22T20:44:00.993522Z","iopub.status.idle":"2024-12-22T20:44:01.834739Z","shell.execute_reply.started":"2024-12-22T20:44:00.993486Z","shell.execute_reply":"2024-12-22T20:44:01.833952Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Callbacks Kullanımı ve Model Eğitimi\n\nBu kod, modelin eğitim sürecini iyileştirmek için `EarlyStopping` ve `ReduceLROnPlateau` callback'lerini kullanır.\n\n### Adımlar:\n1. **EarlyStopping**:\n    - `monitor='val_loss'`: Doğrulama kaybını takip eder.\n    - `patience=5`: 5 epoch boyunca kayıp iyileşmezse eğitimi durdurur.\n    - `restore_best_weights=True`: Eğitim durduğunda en iyi ağırlıkları geri yükler.\n\n2. **ReduceLROnPlateau**:\n    - `monitor='val_loss'`: Doğrulama kaybına göre öğrenme oranını ayarlar.\n    - `factor=0.5`: Öğrenme oranını yarıya indirir.\n    - `patience=3`: 3 epoch boyunca iyileşme olmazsa öğrenme oranını azaltır.\n    - `min_lr=1e-6`: Öğrenme oranının alt sınırını belirler.\n\n3. **Modeli Eğitme**:\n    - `model.fit()` fonksiyonu ile model, eğitim verileri (`X_train`, `y_train`) üzerinde eğitilir.\n    - `validation_data=(X_test, y_test)` parametresi ile doğrulama verisi sağlanır.\n    - `callbacks=[early_stopping, reduce_lr]` ile callback'ler eklenir.\n    - Maksimum 65 epoch, batch boyutu ise 64 olarak belirlenir.\n\n### Çıktı:\n- Modelin eğitim süreci, doğrulama verisi ile izlenir ve callback'ler uygulanır.\n","metadata":{}},{"cell_type":"code","source":"# Callbacks\nearly_stopping = EarlyStopping(\n    monitor='val_loss',  # Doğrulama kaybını takip et\n    patience=5,  # İyileşme olmazsa 5 epoch sonra durdur\n    restore_best_weights=True  # En iyi ağırlıkları geri yükle\n)\n\n# Öğrenme oranını dinamik olarak azalt\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',  # Doğrulama kaybına göre öğrenme oranını güncelle\n    factor=0.5,  # Öğrenme oranını yarıya indir\n    patience=3,  # 3 epoch boyunca iyileşme olmazsa öğrenme oranını azalt\n    min_lr=1e-6  # Minimum öğrenme oranı\n)\n\n# Modeli eğitme\nhistory = model.fit(\n    X_train,  # Eğitim verileri\n    y_train,  # Eğitim etiketleri\n    epochs=65,  # Maksimum epoch sayısı\n    validation_data=(X_test, y_test),  # Doğrulama verisi\n    callbacks=[early_stopping, reduce_lr],  # Callbacks ekleniyor\n    batch_size=64,  # Mini-batch boyutu\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:44:01.835773Z","iopub.execute_input":"2024-12-22T20:44:01.836130Z","iopub.status.idle":"2024-12-22T20:48:43.462935Z","shell.execute_reply.started":"2024-12-22T20:44:01.836084Z","shell.execute_reply":"2024-12-22T20:48:43.460987Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Eğitim Doğruluğu ve Kaybını Görselleştirme\n\nBu kod, modelin eğitim sürecindeki doğruluk ve kayıp değerlerini görselleştirir.\n\n### Adımlar:\n1. **Eğitim Doğruluğu (Accuracy) Grafiği**:\n    - `history.history['accuracy']`: Eğitim doğruluğu.\n    - `history.history['val_accuracy']`: Doğrulama doğruluğu.\n    - X eksenine epoch sayısı, Y eksenine doğruluk değerleri yerleştirilir.\n    - Grafik, eğitim ve doğrulama doğruluğunu aynı anda gösterir.\n\n2. **Eğitim Kaybı (Loss) Grafiği**:\n    - `history.history['loss']`: Eğitim kaybı.\n    - `history.history['val_loss']`: Doğrulama kaybı.\n    - X eksenine epoch sayısı, Y eksenine kayıp değerleri yerleştirilir.\n    - Grafik, eğitim ve doğrulama kaybını karşılaştırarak gösterir.\n\n### Çıktı:\n- İki grafik, eğitim doğruluğu ve kaybının zaman içindeki değişimini görselleştirir.\n","metadata":{}},{"cell_type":"code","source":"# Eğitim doğruluğunu ve kaybını görselleştirme\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()\n\n# Eğitim kaybını görselleştirme\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:48:43.990013Z","iopub.execute_input":"2024-12-22T20:48:43.990804Z","iopub.status.idle":"2024-12-22T20:48:44.372556Z","shell.execute_reply.started":"2024-12-22T20:48:43.990771Z","shell.execute_reply":"2024-12-22T20:48:44.371388Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Karışıklık Matrisi Görselleştirme\n\nBu kod, modelin tahminlerinin doğruluğunu analiz etmek için karışıklık matrisini hesaplar ve görselleştirir.\n\n### Adımlar:\n1. **One-hot Encoding'den Sayısal Etikete Dönüştürme**:\n    - `y_test` birden fazla boyut içeriyorsa (yani, one-hot encoded ise), `np.argmax()` kullanılarak her bir örnek için en yüksek değere sahip olan sınıf etiketi alınır.\n\n2. **Tahminlerin Yapılması**:\n    - `model.predict(X_test)` ile test verisi üzerinden tahminler yapılır.\n    - `np.argmax()` kullanılarak, tahmin edilen sonuçlar sayısal sınıf etiketlerine dönüştürülür.\n\n3. **Karışıklık Matrisi**:\n    - `confusion_matrix(y_test, y_pred)` ile gerçek ve tahmin edilen etiketler arasındaki ilişki hesaplanır.\n\n4. **Karışıklık Matrisi Görselleştirme**:\n    - `sns.heatmap()` ile karışıklık matrisi görselleştirilir.\n    - `annot=True`: Her hücrede sayısal değerler gösterilir.\n    - `fmt='d'`: Değerlerin tam sayı formatında yazdırılması sağlanır.\n    - `cmap='Reds'`: Renk paleti belirlenir.\n    - Etiketler ve başlıklar eklenir.\n\n### Çıktı:\n- Karışıklık matrisi, sınıflar arasındaki tahmin doğruluğunu ve hataları görsel olarak gösterir.\n","metadata":{}},{"cell_type":"code","source":"# Eğer y_test one-hot encoded ise, her bir örnek için en yüksek değeri alarak sayısal etiketlere dönüştür\nif len(y_test.shape) > 1:\n    y_test = np.argmax(y_test, axis=1)\n\n# Gerçek ve tahmin edilen etiketler\ny_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred, axis=1)  # Tahminleri sınıf etiketlerine dönüştür\n\n# Karışıklık Matrisi\ncm = confusion_matrix(y_test, y_pred)\n\n# Etiket isimleri\nclasses = ['collie', 'dolphin', 'elephant', 'fox', 'moose', 'rabbit', 'sheep', 'squirrel', 'giant panda', 'polar bear']\n\n# Grafikleştirme\nplt.figure(figsize=(10, 7))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=classes, yticklabels=classes)\n\n# Başlık ve etiketler\nplt.title('Confusion Matrix')\nplt.ylabel('Gerçek Etiketler')\nplt.xlabel('Tahmin Edilen Etiketler')\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:48:43.465605Z","iopub.status.idle":"2024-12-22T20:48:43.466032Z","shell.execute_reply.started":"2024-12-22T20:48:43.465806Z","shell.execute_reply":"2024-12-22T20:48:43.465828Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modeli Değerlendirme: F1 Skoru Hesaplama\n\nBu kod, modelin performansını değerlendirmek için F1 skorunu hesaplar.\n\n### Adımlar:\n1. **Tahminlerin Yapılması**:\n    - `model.predict(X_test)` ile test verisi üzerinden tahminler yapılır.\n    - `np.argmax()` ile tahmin edilen sınıf etiketleri, çok sınıflı sınıflandırma için alınır.\n\n2. **F1 Skoru Hesaplama**:\n    - `f1_score(y_test, y_pred_classes, average='weighted')`: Gerçek etiketler (`y_test`) ve tahmin edilen etiketler (`y_pred_classes`) arasındaki F1 skoru hesaplanır.\n    - `average='weighted'`: F1 skoru tüm sınıfların ağırlıklı ortalamasını alır.\n\n### Çıktı:\n- Hesaplanan F1 skoru, modelin genel doğruluğunu ve dengesini değerlendirmek için kullanılır.\n","metadata":{}},{"cell_type":"code","source":"# Modeli değerlendirme\ny_pred = model.predict(X_test)  # Tahminler\ny_pred_classes = np.argmax(y_pred, axis=1)  # Çok sınıflı sınıflandırma için sınıf etiketlerini al\n\n# F1 Skoru hesaplama\nf1 = f1_score(y_test, y_pred_classes, average='weighted')  # 'weighted' tüm sınıfların ağırlıklı ortalamasını alır\n\nprint(f\"F1 Score: {f1}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:48:43.468064Z","iopub.status.idle":"2024-12-22T20:48:43.468524Z","shell.execute_reply.started":"2024-12-22T20:48:43.468291Z","shell.execute_reply":"2024-12-22T20:48:43.468313Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modeli Kaydetme\n\nBu kod, eğitilmiş modelin `.h5` formatında kaydedilmesini sağlar.\n\n### Adımlar:\n1. **Modeli Kaydetme**:\n    - `model.save('trained_model.h5')`: Modelin ağırlıkları, yapılandırması ve eğitim durumu `.h5` uzantılı bir dosyaya kaydedilir.\n  \n### Çıktı:\n- `trained_model.h5` adıyla kaydedilen dosya, modelin ileride tekrar kullanılabilmesi için saklanır.\n","metadata":{}},{"cell_type":"code","source":"model.save('trained_model.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:48:43.469846Z","iopub.status.idle":"2024-12-22T20:48:43.470188Z","shell.execute_reply.started":"2024-12-22T20:48:43.470002Z","shell.execute_reply":"2024-12-22T20:48:43.470018Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Görsel Manipülasyonu ve Veri Hazırlığı\n\nBu kod parçası, belirli bir dizindeki görselleri yükler, her birini belirli bir boyutta yeniden boyutlandırır, normalizasyon uygular ve ardından ışık manipülasyonu (parlaklık artışı) uygular.\n\n### 1. `get_manipulated_images` Fonksiyonu:\n- **Kullanım**: Görüntüye parlaklık ekler.\n- **Girdi**: Görüntü (image), parlaklık değeri (brightness).\n- **Çıktı**: Parlaklık artırılmış görüntü.\n\n### 2. Görselleri Yükleme ve Manipüle Etme:\n- **İşlem**:\n  - `classes` dizisindeki her sınıf için görseller yüklenir.\n  - Görseller, 224x224 boyutlarına yeniden boyutlandırılır.\n  - Görseller normalize edilir (0-255 arası değerler 0-1 arası dönüştürülür).\n  - Görüntüye parlaklık manipülasyonu uygulanır.\n  \n- **Çıktı**: Manipüle edilmiş görseller `X_manipulated` ve etiketler `y_manipulated` listelerinde toplanır.\n\n### 3. Veri Seti:\n- **X_manipulated**: Manipüle edilmiş görsellerin dizisi.\n- **y_manipulated**: Etiketler dizisi.\n- **Boyut**: `X_manipulated.shape` ve `y_manipulated.shape` ile veri setinin boyutu yazdırılır.\n\n","metadata":{}},{"cell_type":"code","source":"def get_manipulated_images(image, brightness=50):\n    # Görüntüye ışık ekleme\n    manipulated_img = cv2.convertScaleAbs(image, alpha=1, beta=brightness)\n    return manipulated_img\n\n# Görselleri yükleme ve manipüle etme\nX_manipulated = []\ny_manipulated = []\n\nfor label_idx, class_name in enumerate(classes):\n    class_dir = os.path.join(image_dir, class_name)\n    \n    if os.path.exists(class_dir):\n        images = os.listdir(class_dir)\n        selected_images = images[:650]\n        \n        for img_name in selected_images:\n            img_path = os.path.join(class_dir, img_name)\n            img = cv2.imread(img_path)\n            img_resized = cv2.resize(img, (224, 224))  # 224x224 boyutunda\n            img_normalized = img_resized / 255.0  # Normalizasyon\n            \n            # Işık manipülasyonu\n            manipulated_img = get_manipulated_images(img_normalized)\n            X_manipulated.append(manipulated_img)\n            y_manipulated.append(label_idx)\n\nX_manipulated = np.array(X_manipulated)\ny_manipulated = np.array(y_manipulated)\n\nprint(f\"Manipüle edilmiş görsel setinin boyutu: X: {X_manipulated.shape}, y: {y_manipulated.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:48:43.470998Z","iopub.status.idle":"2024-12-22T20:48:43.471299Z","shell.execute_reply.started":"2024-12-22T20:48:43.471160Z","shell.execute_reply":"2024-12-22T20:48:43.471174Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Renk Sabitliği ve Görsel Manipülasyonu\n\nBu kod parçası, belirli bir dizindeki görselleri yükler, her birini belirli bir boyutta yeniden boyutlandırır, normalizasyon uygular ve ardından renk sabitliği (Gray World algoritması) uygular.\n\n### 1. `get_wb_images` Fonksiyonu:\n- **Kullanım**: Görüntüye renk sabitliği (Gray World) algoritması uygular.\n- **İşlem**:\n  - Görüntüdeki her renk kanalının (kırmızı, yeşil, mavi) ortalama değeri hesaplanır.\n  - Bu değerler, her renk kanalını ortalama değere getirecek şekilde ölçeklendirilir.\n- **Çıktı**: Renk sabitliği uygulanmış görüntü.\n\n### 2. Görselleri Yükleme ve Manipüle Etme:\n- **İşlem**:\n  - `classes` dizisindeki her sınıf için görseller yüklenir.\n  - Görseller, 224x224 boyutlarına yeniden boyutlandırılır.\n  - Görseller normalize edilir (0-255 arası değerler 0-1 arası dönüştürülür).\n  - Renk sabitliği uygulanır.\n  \n- **Çıktı**: Renk sabitliği uygulanmış görseller `X_wb` ve etiketler `y_wb` listelerinde toplanır.\n\n### 3. Veri Seti:\n- **X_wb**: Renk sabitliği uygulanmış görsellerin dizisi.\n- **y_wb**: Etiketler dizisi.\n- **Boyut**: `X_wb.shape` ve `y_wb.shape` ile veri setinin boyutu yazdırılır.\n\n","metadata":{}},{"cell_type":"code","source":"def get_wb_images(image):\n    # Renk sabitliği algoritması (Gray World)\n    avg_b = np.mean(image[:, :, 0])\n    avg_g = np.mean(image[:, :, 1])\n    avg_r = np.mean(image[:, :, 2])\n    \n    avg = (avg_b + avg_g + avg_r) / 3\n    image[:, :, 0] = image[:, :, 0] * (avg / avg_b)\n    image[:, :, 1] = image[:, :, 1] * (avg / avg_g)\n    image[:, :, 2] = image[:, :, 2] * (avg / avg_r)\n    \n    return image\n\n# Manipüle edilmiş görsellere renk sabitliği ekleyelim\nX_wb = []\ny_wb = []\n\nfor label_idx, class_name in enumerate(classes):\n    class_dir = os.path.join(image_dir, class_name)\n    \n    if os.path.exists(class_dir):\n        images = os.listdir(class_dir)\n        selected_images = images[:650]\n        \n        for img_name in selected_images:\n            img_path = os.path.join(class_dir, img_name)\n            img = cv2.imread(img_path)\n            img_resized = cv2.resize(img, (224, 224))  # 224x224 boyutunda\n            img_normalized = img_resized / 255.0  # Normalizasyon\n            \n            # Renk sabitliği uygula\n            wb_img = get_wb_images(img_normalized)\n            X_wb.append(wb_img)\n            y_wb.append(label_idx)\n\nX_wb = np.array(X_wb)\ny_wb = np.array(y_wb)\n\nprint(f\"Renk sabitliği uygulanmış görsel setinin boyutu: X: {X_wb.shape}, y: {y_wb.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:48:43.472508Z","iopub.status.idle":"2024-12-22T20:48:43.472813Z","shell.execute_reply.started":"2024-12-22T20:48:43.472670Z","shell.execute_reply":"2024-12-22T20:48:43.472685Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modeli Test Etme ve Doğrulama\n\nBu kod, daha önce eğitilmiş bir modeli yükler ve manipüle edilmiş ve renk sabitliği uygulanmış görsel setleri üzerinde test eder. Test sonuçları doğruluk oranı olarak raporlanır.\n\n### 1. Model Yükleme:\n- **Yöntem**: `load_model('trained_model.h5')`\n  - `trained_model.h5` dosyasındaki eğitilmiş model yüklenir.\n\n### 2. Test Fonksiyonu:\n- **Fonksiyon**: `test_model(model, X_test, y_test)`\n  - **Girdi**:\n    - `model`: Eğitilmiş model.\n    - `X_test`: Test görselleri.\n    - `y_test`: Gerçek etiketler.\n  - **İşlem**:\n    - Model, test verisi (`X_test`) üzerinde tahmin yapar.\n    - Tahminler, sınıf etiketlerine dönüştürülür.\n    - Gerçek etiketlerle karşılaştırılarak doğruluk hesaplanır.\n  - **Çıktı**: Test doğruluğu yazdırılır.\n\n### 3. Test İşlemleri:\n- **Manipüle Edilmiş Görseller ile Test**: `X_manipulated` ve `y_manipulated` veri setleri ile model test edilir.\n- **Renk Sabitliği Uygulanmış Görseller ile Test**: `X_wb` ve `y_wb` veri setleri ile model test edilir.\n\n### 4. Sonuç:\n- Her iki test seti için doğruluk oranları ekrana yazdırılır.\n","metadata":{}},{"cell_type":"code","source":"# Eğitilmiş modelinizi yükleyin\nmodel = load_model('trained_model.h5')\n\n# Modeli test etme\ndef test_model(model, X_test, y_test):\n    predictions = model.predict(X_test)\n    predictions = np.argmax(predictions, axis=1)\n    accuracy = accuracy_score(y_test, predictions)\n    print(f\"Test doğruluğu: {accuracy * 100:.2f}%\")\n\n# Manipüle edilmiş set ile testi yapalım\ntest_model(model, X_manipulated, y_manipulated)\n\n# Renk sabitliği uygulanmış set ile testi yapalım\ntest_model(model, X_wb, y_wb)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T20:48:43.473643Z","iopub.status.idle":"2024-12-22T20:48:43.473928Z","shell.execute_reply.started":"2024-12-22T20:48:43.473790Z","shell.execute_reply":"2024-12-22T20:48:43.473805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}